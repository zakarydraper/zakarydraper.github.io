---
---
For my thesis I am investigating the use of supervised learning algorithms for developing factor and component retention rules for use with common factor analysis (CFA) and principal components analysis (PCA). Both CFA and PCA are widely used in a variety of disciplines including psychology, finance, marketing, and biology. Researchers use these methods to identify the important dimensions underlying the variance in their data. This is accomplished by deriving latent variables. The goal being that the variation in many observed variables can be represented using a small number of derived latent variables.

Unfortunately, both CFA and PCA derive a number of latent variables equal to the number of observed variables in the dataset. Many of these derived variables describe only trivial amounts of variance in the observed variables, are not easily interpretable, and are unlikely to replicate in future studies (that is, they are idiosyncratic to the data at hand). Because of this, it is necessary for the researcher to discard many of the derived variables in order to reach a solution that is meaningful. Discarding too many latent variables means that the researcher will be throwing away useful information; discarding too few means that at least one of the latent variables is not meaningful and interpreting it could be misleading. As such, is it important to retain exactly the correct number of latent variables.

The number of latent variables retained is a subjective decision made by the researchers. There are no perfect rules for making this determination and it is likely that there never can be. Statisticians have proposed a variety of methods to help with this decision, each being more or less successful depending on the characteristics of the data. The current gold standard method is parallel analysis which involves retaining only those latent variables which describe more variance in the observed variables than latent variables derived from randomly generated datasets. Although parallel analysis is highly accurate under many conditions, its accuracy diminishes under conditions which are common to real-world datasets, such as low component or factor loadings.

For my thesis, I am utilizing supervised learning algorithms to integrate several previously developed methods into a single, highly accurate method that is applicable to datasets with a variety of characteristics. This novel approach to the number of factors problem should be as accurate or better than any one of the previously proposed methods.
